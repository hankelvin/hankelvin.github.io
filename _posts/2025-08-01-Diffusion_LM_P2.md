---
layout:     post
title:      "Diffusion Language Models -- Part Two (What kinds are there and how is one trained?)"
date:       2025-08-01 01:00:00
categories: jekyll css
---

{% newthought "There are three variants of diffusion language models" %} (__DLMs__), and the nuances of each impact their training, inference and scalability. I think it will be helpful to situate them amongst each other before we proceed further; and so in this post, I will first introduce the variants, discuss their differences as well as what they mean. I will then go on to outline the training procedure for the Masked (__MDLM__) variant as it is currently receiving significant amounts of attention in research{% sidenote "sidenote-vogue" "And quite importantly, with useful extensions into multimodality and reinforcement learning already carried out with them." %}, before ending off with a summary of two interesting pieces of DLM research{% sidenote "sidenote-research" "
<br>‚óºÔ∏è (Wen et al, 2025) [The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs](https://arxiv.org/abs/2507.11097) 
<br> ‚óºÔ∏è (Prabhudesai et al, 2025) [Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/abs/2507.15857)" %} that surfaced recently along with thoughts on their broader implications. If you wish, you can use these links to skip to the specific sections of this post: [1. DLM variants](#-1-what-variants-of-dlms-are-there); [2. Comparing the variants](#-2-apple-to-apple-whats-the-benefit-of-one-over-another); [3. Training a masked DLM](#-3-what-is-the-training-procedure-for-a-dlm); and [4. Recent findings and potential implications](#-4-whats-come-up-recently-in-dlm-research)
<!-- NOTE: "-" needed for space between emoji and first word -->

### üé® 1. What variants of DLMs are there? 
DLM approaches can be described as being of the (i) __Gaussian__, (ii) __Uniform__, or (iii) __Masked__ variants, based on how the original training data instances{% sidenote "sidenote-datainstance" "for e.g. an instance could be a sentence such as \"dogs are our friends\" for the language modeling task." %} are "corrupted" (or how the notion of noise is conceptualised and how it is introduced into the input during the foward process{% sidenote "sidenote-reverse" ". . . and hence (by design) the reverse process as well."%}). The first two are named for the distributions they use to draw noise from, and the third is named for a special token (e.g. ```[MASK]```) added to the vocabulary to give a noised state that "masks" the original token. To give a more concrete feel of each variant, I will use the following toy example to illustrate some of them.

<div style="background-color: #249ae9ff; max-width: 50%; color: white; padding: 20px; border-radius: 8px; margin: 10px;">
  <h3 style="margin: 0 0 15px 0; width: 100%;">Settings for a toy example</h3>   
  <p style="margin: 0; width: 100%; text-align: justify;">   
    Imagine we have a toy language with 13 lexical units in the vocabulary V = <em>{"we", "you", "they", "our", "your", "their", "cat", "dog", "friend", "is", "are", "s", "[PAD]"}</em>, which allows one to form sequences such as <em>"dog s are our friend s"</em>, <em>"our dog s are your s"</em>, <em>"your cat is our friend"</em> etc. 
    <br><br>
    <small><small>The special marker [PAD] is used as a filler to ensure that all sequences are of the same length, e.g. "<em>your cat is our friend [PAD]</em>", so that it has the same six-unit length as the other two dog-sentences, allowing us to do batched generations.</small></small>
  </p>
</div>

‚óºÔ∏è __Gaussian (GDLM)__: This variant, also referred to as "continuous-time" in the literature, is the closest in form to the ones that are found in image diffusion models{% sidenote "sidenote-imagediff" "Such as Google's [Imagen](https://deepmind.google/models/imagen/), OpenAI's [DALL-E](https://openai.com/index/dall-e-3/) and Stability AI's [Stable Diffusion](https://stability.ai/stable-image)" %}, so if you are familiar with them, then the GDLM models could be quite familiar to you. The architecture here involves: (i) embedding the tokens of a sequence so that each of them are represented with real-valued vectors{% sidenote "sidenote-embed" "This is similar to the first step in auto-regressive LLMs (__AR-LLMs__) (for Transformers as well as RNNs)." %}, and (ii) adding to them noise that is in the form of random vectors drawn from a Gaussian distribution $$ \epsilon_{t} $$ ~ $$ N(\mu_{t}, \sigma_{t}^2) $$ at each step. Using the toy example, what this means in practice is that we will keep a look-up table for 13 random vectors (one for every unit in our toy language's vocabulary) and each vector is of a dimension $$d$$. So the sequence <em>"dog s are our friend s"</em> will be represented by six token vectors, and we will add noise to each token vector such that every token is completely gaussian at the limit of the forward process i.e. $$t \to \infty$$ (or in practice, some defined terminal timestep $$T$$ so that the total noise added is known; it is usually set at 1.0 in diffusion models). A few formulations have been proposed for learning these models, including score-matching which appears most commonly, as well as latent variable models and stochastic differential equations, for learning the reverse process <a href='https://arxiv.org/abs/2211.15089' title='Continuous diffusion for categorical data'>(Dieleman et al, 2023)</a>. Examples of GDLMs include (i) Diffusion-LM <a href='https://arxiv.org/abs/2205.14217' title='Diffusion-LM Improves Controllable Text Generation'>(Li et al, 2022)</a> that appeared in 2022 and which first drew attention towards diffusion modeling for text generation, (ii) CDCD <a href='https://arxiv.org/abs/2211.15089' title='Continuous diffusion for categorical data'>(Dieleman et al, 2023)</a>, and (iii) PLAID <a href='https://arxiv.org/abs/2305.18619' title='Likelihood-Based Diffusion Language Models'>(Gulrajani & Hashimoto, 2023)</a>. 

<!-- {% sidenote "sidenote-early-discrete" "Earlier models examined diffusion for discrete sequences such as music <a href='https://arxiv.org/abs/2103.16091' title='Symbolic Music Generation with Diffusion Models'>(Mittal et al, 2021)</a>, but not specifically on language and at the same scale of a language model. Initial explorations can be found in some of a few earlier discrete diffusion work such as <a href='https://arxiv.org/abs/2107.03006' title='Structured Denoising Diffusion Models in Discrete State-Spaces'>(Austin et al, 2021)</a> -- see ¬ß3.1 there" %} -->

‚óºÔ∏è __Uniform (UDLM)__: Instead of the real-valued embedding vectors used in GDLMs, this approach represents each token of a sequence with a one-hot vector{% sidenote "sidenote-onehot" "i.e. the vector for each token is a dirac distribution with all probability mass concentrated at the actual token's index in the vocabulary." %}; of dimensions the size of the vocabulary; whereby it is 1 at the position of the token in the vocabulary, and 0 elsewhere. Here, the notion of adding noise to the data instance{% sidenote "sidenote-udlmnoise" "Note that noise is added/removed independently between each token in the sequence -- \"_We make the assumption that the forward noising process is applied independently across a sequence... the denoising process factorizes independently across tokens._\" <a href='https://arxiv.org/abs/2406.07524' title='Simple and Effective Masked Diffusion Language Models'>(Sahoo et al, 2024)</a> " %} is via the application of some transition matrix ($$Q_t$$, determining the probabilities for whether the token stays unchanged or to which one of the other vocab units) such that the initially concentrated probability mass in the token vector gradually distributes over all of the other vocab units. At the limit of the forward process, the one-hot vector applied with $$ Q_{t=T} $$ would give a uniform distribution (i.e. each vocab unit is equally likely; there is completely no useful signal to deduce what the original token was) and also reach stationarity, i.e. additional steps cannot change from the uniform distribution. Examples of this approach include the ```Uniform``` versions of the models trained in <a href='https://arxiv.org/abs/2310.16834' title='Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution'>(Lou et al, 2023)</a> and <a href='https://arxiv.org/abs/2310.16834' title='Simple Guidance Mechanisms for Discrete Diffusion Models'>(Schiff et al, 2025)</a>.{% sidenote "sidenote-wheel-udlm" "To extend the __Wheel__ analogy to UDLM: (i) instead of each panel on the gameboard being two-sided (being either white/blank or a character), they would be \|$$V$$\|-sided (i.e. as many sides as the vocabulary and without white/blank), (ii) the gameboard will start with some completely scrambled combination of characters, and (iii) at every guess, the contestant can flip multiple panels to any other character in the vocabulary. Another way to look at it could be as a slots machine (see GIF below)." %}

{% marginfigure "marginfigure-slots" "assets/img/udlm.gif" "Source: Slots GIF -- [https://discrete-diffusion-guidance.github.io/](https://discrete-diffusion-guidance.github.io/)"%}

‚óºÔ∏è __Masked (MDLM)__: This is also referred to as modeling discrete diffusion with an "absorbing state", first appearing in <a href='https://arxiv.org/abs/2107.03006' title='Structured denoising diffusion models in discrete state-spaces'>(Austin et al, 2021)</a>. Essentially, noise is represented by the special token mentioned above{% sidenote "sidenote-maskexp" " for e.g., the sentence <em>\"dog s are our friend s\"</em> could be gradually masked to \"dog [MASK] are our [MASK] s\" and finally to \"[MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\" " %}, i.e. a token in the original sequence is corrupted by being "absorbed" into this special state (rather than transitioning to others). This is an important characteristic of most current MDLMs, i.e. in the forward process, once a token transitions to ```[MASK]```, it stays in that state throughout the subsequent steps. Conversely, in the reverse process, once a ```[MASK]``` token transitions to a vocab unit $$v$$ other than ```[MASK]```, it also stays as $$v$$ in all subsequent steps.{% sidenote "sidenote-wheelmdlm" "This variant matches the __Wheel__ analogy in the previous [post](https://hankelvin.github.io/articles/25/Diffusion_LM_P1); the white panels correspond to the ```[MASK]``` token, behind each white panel is one character and once a contestant makes a ~~correct~~ any guess for it, it cannot be changed." %} MDLM is the basis for the LLaDA <a href='https://arxiv.org/abs/2502.09992' title='Large Language Diffusion Models'>(Nie et al, 2024)</a> and Dream <a href='https://hkunlp.github.io/blog/2025/dream' title='Dream 7B'> (Ye et al, 2025)</a> models, as well as well as multimodal versions such as LLaDA-V <a href='https://arxiv.org/abs/2505.16933' title='LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning'>(You et al, 2025)</a> and MMaDA <a href='https://arxiv.org/abs/2505.15809' title='MMaDA: Multimodal Large Diffusion Language Models'>(Yang et al, 2025)</a>, It was also explored in SEDD <a href='https://arxiv.org/abs/2310.16834' title='Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution'>(Lou et al, 2023)</a>, which Inception Lab's Mercury models are reportedly based on{% sidenote "sidenote-mercury" "The Mercury technical report <a href='https://arxiv.org/abs/2506.17298' title='Mercury: Ultra-Fast Language Models Based on Diffusion'>(Inception Labs, 2025)</a> state that \"_Our methods extend <a href='https://arxiv.org/abs/2310.16834' title='Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution'>(Lou et al, 2023)</a> through careful modifications to the data and computation to scale up learning._\". Although they do not state which of the MDLM or UDLM variant they studied in (Lou et al, 2023) they ended up leveraging, it seems possible that the GDLM approach was taken given the poorer perplexity figures obtained by UDLM in their work as well as in earlier work." %}. 

<ins>__Light round-up:__</ins> At the limit $$T$$ in their forward processes, each class of DLM can be summarised as follows: for GDLMs each token in a sequence can transition to any other token (state) reachable by the accumulated variance of the sampled noise; for UDLMs, each token can transition to any other state with equal probability; and in the case of MDLMs, each token lands on the special ```[MASK]``` token. 

<ins>__MDLM connections with BERT:__</ins> Recall that BERT <a href='https://arxiv.org/abs/1810.04805' title='BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'>(Devlin et al, 2018)</a> -- an encoder-only model that could be used for tasks such as cloze-style QA{% sidenote "sidenote-cloze" "e.g the most likely token after <em>\"Paris is the capital of\"</em> is <em>\"France\"</em>. " %} and which is a precursor to the LLMs of today -- was trained with a masked language modeling objective, i.e. random portions (~15%) of the sentences in the training data are masked, and the model has to learn to predict the masked words. This is very similar to the MDLM approach, except that in MDLMs this unmasking is done across multiple steps (instead of a single pass), and for the entire sequence (the last MDLM inference step would most closely align with the task in the BERT MLM objective). Accordingly, some work have explored leveraging BERT-style (i.e. encoder-only) models for DLM: see DiffusionBERT <a href='https://aclanthology.org/2023.acl-long.248' title='DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models'>(He et al, 2023)</a> which propose further training BERT with time-embeddings with a special diffusion noise schedule to use it _√† la DLM_. See also _'Comparison to BERT'_ in ¬ß6 of <a href='https://arxiv.org/abs/2406.07524' title='Simple and Effective Masked Diffusion Language Models'>(Sahoo et al, 2024)</a> for a discussion on this connection.


### üçè 2. Apple-to-apple: what's the benefit of one over another?
There is more focus on MDLM and UDLM over GDLM currently, as the latter has been met with comparably less success (in terms of achievable perplexity).{% sidenote "sidenote-clamp" "The reason for this is because the question of how to reconcile the noised real-valued vectors in GDLM to discrete space is not trivial and required many special tricks for training and inference to work. For instance, it was necessary to use nearest neighbour search and clamping to a valid token vector at every reverse diffusion step in Diffusion-LM <a href='https://arxiv.org/abs/2205.14217' title='Diffusion-LM Improves Controllable Text Generation'>(Li et al, 2022)</a> to reach comparable performance with AR-LLMs." %} In the most recent round of published DLM research (i.e. ICLR and ICML in 2025), significant attention has been focused on MDLM approaches{% sidenote "sidenote-duo" "Though it should be noted that interesting work on GDLM & UDLM is also continuing, I think notably in <a href='https://arxiv.org/abs/2506.10892' title='The Diffusion Duality'>(Sahoo et al, 2025)</a>, where they work out a proof that connects UDLM as a special case of GDLM using the argmax operator, and opens up the possibility to leverage techniques in GDLM for training and inferencing on UDLM." %}, as they achieve better perplexity compared to UDLM{% sidenote "sidenote-perplexity" "Note that lower is better for perplexity; compare the SEDD (Uniform) and SEDD (Absorb) results in Table 1 of <a href='https://arxiv.org/abs/2310.16834v2' title='Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution'>(Lou et al, 2025)</a>; as well as D3PM uniform vs D3PM absorbing in Figure 2 and Table 2 of <a href='https://arxiv.org/abs/2107.03006' title='Structured Denoising Diffusion Models in Discrete State-Spaces'>(Austin et al, 2021)</a>." %}. Intuitively, this is not unexpected, as it would seem easier to learn an MDLM (where transitions are constrained once the absorbing ```[MASK]``` state is reached in the forward process) compared to UDLM (where transitions at each timestep could be to any other tokens, i.e. a much larger space of posssible transitions). 

<!-- - "such as efficient sampling algorithms based on advanced ODE solvers, or classifier-free guidance." (Dieleman et al, 2023) -->
However, several shortcomings of the MDLM approach have been raised (hence the continued research interests in GDLM and UDLM approaches). Chief amongst them include: (i) the potentially over-restrictiveness of the vanilla MDLM masking/unmasking procedure{% sidenote "sidenote-vanillamaskinference" "I use \"vanilla\" because there are approaches emerging that propose more advanced inference procedures such as remasking that could address this. For instance <a href='https://arxiv.org/abs/2503.00307' title='Remasking discrete diffusion models with inference-time scaling'>(Wang et al, 2025)</a>" %}; and (ii) the difficulty of introducing classifier-free guidance into MDLMs.

‚óºÔ∏è regarding shortcoming (i): "__Self-correction__" is a term for referring to how tokens can continue to transition to others over the reverse diffusion steps; it is connected to the "coarse-to-fine" property (in the truest sense) that DLMs are frequently touted to beneficially possess over AR-LLMs. While self-correction is inherently possible in GDLMs and UDLMs given their design{% sidenote "sidenote-predictor" "<ins>_Sidenote:_</ins> they could also be steered with predictor-corrector models like in image diffusion models <a href='https://openreview.net/forum?id=VM8batVBWvg' title='Discrete Predictor-Corrector Diffusion Models for Image Synthesis'>(Lezama et al, 2023)</a>" %}, it is not possible with MDLM (without some engineering). Theoretically, this lack of self-correction could give rise to errors in the inference steps, which would then propagate{% sidenote "sidenote-selfcorrect" "To give a concrete example, say we start from \"[MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\", errors (e.g. in modeling learning) could bring us to \"[MASK] [MASK] are your s [PAD]\" and since unmasked tokens cannot transition any further, this leaves limited choice but to go to \"our dog are your s [PAD]\" resulting in a number agreement error. <br><ins>_Sidenote:_</ins> It could be interesting to carry out a study at-scale of the tokens (and the types of words they form) that get unmasked across the MDLM inference steps -- e.g. see Figures 10-15 of <a href='https://arxiv.org/abs/2107.03006' title='Structured Denoising Diffusion Models in Discrete State-Spaces'>(Austin et al, 2023)</a>, and establish whether there are any significant patterns in what parts of a sentence/paragraph gets unmasked and fixed first." %}. That said, some recent studies proposed remasking strategies to address such issues -- e.g. <a href='https://arxiv.org/abs/2407.21243' title='Informed Correctors for Discrete Diffusion Models'>(Zhao et al, 2025)</a>, <a href='https://arxiv.org/abs/2502.09992' title='Large Language Diffusion Models'>(Nie et al, 2024)</a>. <a href='https://arxiv.org/pdf/2503.00307v1' title='Remasking Discrete Diffusion Models with Inference-Time Scaling'>(Wang et al, 2025)</a> also claim to provably show the soundness of applying remasking without needing to take special considerations into the training and inference of MDLMs. In practice, the LLaDA authors (Nie et al, 2025) were able to reach AR-LLM performance for their model whilst leveraging generation with remasking strategies (see ¬ß2.4 of their paper). 

‚óºÔ∏è regarding shortcoming (ii): __Guidance__ originates from diffusion modeling for image and refers to conditioning information (for instance a label such as "dogs", or a text prompt such as "friendly-looking dogs") we can add to "guide" the reverse diffusion process towards generating an image with certain desired properties.{% sidenote "sidenote-cfg" "This was initially proposed with the use of gradients from a classifier <a href='https://arxiv.org/abs/2105.05233' title='Diffusion models beat GANs on image synthesis'>(Dhariwal & Nichol, 2021)</a> that can identify the classes of the images during training; but since training is over a diffusion process, the classifier had to be trained to be able to identify the classes across the noising process, which can be complicated to achieve. <a href='https://arxiv.org/abs/2207.12598' title='Classifier-Free Diffusion Guidance'>(Ho & Salimans, 2022)</a> established a more efficient and effective to train an image diffusion model for guidance without the need for a separate classifier (classifier free guidance, or __CFG__) which is now widely used. See this Sander Dieleman [post]((https://sander.ai/2022/05/26/guidance.html)) for an overview. For a more visual explanation of CFG (and also diffusion models in general), have a look at this recent [Welch Labs-3Blue1Brown explainer](https://youtu.be/iv-5mZ_9CPY?t=1791)." %} Guidance is useful for DLM too, as a way to steer towards safety and better matching user intent, for e.g. to adhere to style requirements or reflect concepts such as non-toxicity, inclusivity, empathy, neutrality etc. An example of such work is DGLM <a href='https://aclanthology.org/2024.findings-acl.887' title='Diffusion Guided Language Modeling'>(Lovelace et al, 2024)</a> which uses a GDLM to produce a "candidate" continuation of a prompt plus some guidance condition, which{% sidenote "sidenote-cand" "The input to the AR-LLM is the probability distribution of the candidate denoised/\"refined\" by the GDLM from noise." %} is then put through a decoder-only AR-LLM to verbalise.{% sidenote "sidenote-weinberger" "For a quick overview: see Kilian Weinberger's [presentation](https://youtu.be/klW65MWJ1PY?t=2757) on the work." %} However, standard classifier-free guidance (__CFG__) are designed with diffusion models trained with the score-matching objective (which learns a model to match the _score_, or the gradient of the log probability density function with respect to the data) in mind. Score-matching in the continuous sense is not used for MDLMs{% sidenote "sidenote-discretescore" "Though there is concrete score matching <a href='https://arxiv.org/pdf/2211.00802' title='Concrete Score Matching: Generalized Score Matching for Discrete Data'>(Meng et al, 2023)</a> for the discrete case (modified in SEDD <a href='https://arxiv.org/abs/2310.16834' title='Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution'>(Lou et al, 2023)</a>), it is an approximation and does not address how classical guidance (as in the continuous setting for images) can be applied (without potentially scrambling the discrete semantics). Moreover, recent MDLM work such as in the LLaDA family of models directly set the training objective as the cross-entropy loss on the masked tokens (Eq 3 in <a href='https://arxiv.org/pdf/2502.09992' title='Large Language Diffusion Models'>(Nie et al, 2025)</a>), a further departure from the score-matching formulation for learning DLMs." %} hence it is not feasible to transfer existing CFG techniques to MDLMs. Notably however, <a href='https://arxiv.org/abs/2410.18514' title='Scaling up Masked Diffusion Models on Text'>(Nie at al, 2024)</a> proposed _unsupervised classifier-free guidance_, a training objective to allow CFG in MDLMs without using paired data (e.g. prompt-continuation, question-answer); they found that unsupervised CFG fine-tuning of an MDLM gives better performance compared to using standard CFG. 

### üèãÔ∏è‚Äç‚ôÄÔ∏è 3. What is the training procedure for a DLM?
To get a general sense of the DLM training procedure, it will be useful to look at the LLaDA approach as it includes language model pretraining and instructions fine-tuning, both of which are fundamental for general-purpose LLM usage. Note that most work parameterise their DLMs using the Transformer architecture{% sidenote "sidenote-transformer" "Paralleling the trend in image diffusion too <a href='https://arxiv.org/pdf/2202.04200' title='MaskGIT: Masked Generative Image Transformer'>(Chang et al, 2022)</a> as well as <a href='https://arxiv.org/pdf/2212.09748' title='https://arxiv.org/pdf/2212.09748'>(Peebles & Xie, 2023)</a>" %}, but this is not a must.{% sidenote "sidenote-rush" "Alexander Rush has a useful [explainer video](https://www.youtube.com/watch?v=WjAUX23vgfg) of diffusion models for text in general."%} Here I will briefly touch on two key areas of the training procedure: (i) the noising in the forward process, and (ii) the training objective. For more details and code on LLaDA's training, see their [blogpost](https://ml-gsai.github.io/LLaDA-demo/) and [codebase](https://github.com/ML-GSAI/LLaDA/blob/main/GUIDELINES.md). 

<br>

{% maincolumn "assets/img/llada_training.png" "Image source: illustrating the masking and prediction procedure for MDLM pretraining and fine-tuning -- <a href='https://arxiv.org/pdf/2502.09992' title='Large Language Diffusion Models'> (Nie et al, 2025)</a> <br><br>"%}

‚óºÔ∏è __Noising:__ The general idea is to sample some noise level for a given data instance (see graphic above for how masking is done for pretraining and for instructions fine-tuning) which will be used to determine the tokens to mask (e.g. in footnote 10 above on the sequence ‚Äúdog s are our friend s‚Äù) in the forward process. The noising schedule (e.g. linear, geometric or even cosine) can impact performance; for instance, if we model it such that masking is at a slower rate as $$t \to T$$ in the forward process, then this would align with an unmasking sequence in the reverse denosing process where we unmask comparatively fewer tokens at first before gradually increasing.{% sidenote "sidenote-schedule" "Intuitively, this makes sense since tokens are unmasked independently of each other at each time step, and given the fixedness in MDLMs unmasking, we want fewer commitments at the start to reduce the unmasking of conflicting tokens, which will go on to compound in subsequent steps." %} In practice, multiple epochs (up to 64x, see <a href='https://arxiv.org/pdf/2305.18619' title='Likelihood-Based Diffusion Language Models'>(Gulrajani & Hashimoto, 2023)</a>) of training over the data, with (almost likely) different noise sampled on the same data instance, is required for DLMs to reach the same level of performance on perplexity as AR-LLMs (which are typically trained with a single epoch over the data); while less efficient to train, it is this procedure that imbues the DLM to be able to generate non-autoregressively. 

‚óºÔ∏è __Training objective:__ In the earliest diffusion models, the training objective involves having to compute the evidence lower bound (ELBO){% sidenote "sidenote-elbo" "Unlike AR-LLMs which factorise the likelihood of a sequence into conditional probabilities (i.e. probability over the vocabulary at every step) which make it easier to evaluate, likelihood of a sequence (which is how we model in DLM) is intractable, hence the use of ELBO." %}; subsequently, the a simplification to ELBO was proposed with the score-matching approach{% sidenote "sidenote-score" "<a href='https://arxiv.org/pdf/2006.11239' title='Denoising Diffusion Probabilistic Models'>(Ho et al, 2020)</a> showed that the original ELBO in the diffusion objective can be further simplified by modeling the probability distributions as _scores_ (gradient of the log prob with respect to the data), and the objective can be reduced to minimising the mean-squared error of the entries in the predicted score vector and the true score, which is substantially easier to do."%}. Since the noise level varies across time, it was also included in a time variable (for e.g. as an additional embedding in CDCD). Recently, it was shown (quite concurrently, based on version dates on arxiv) in MD4 <a href='Simplified and Generalized Masked Diffusion for Discrete Data' title='Simplified and Generalized Masked Diffusion for Discrete Data'>(Shi et al, 2024)</a>, M-DLM <a href='https://arxiv.org/pdf/2406.07524' title='Simple and Effective Masked Diffusion Language Models'>(Sahoo et al, 2024)</a> and RADD <a href='https://arxiv.org/abs/2406.03736' title='Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data'>(Ou et al, 2024)</a> that a tighter bound could be obtained by modeling the predictions of the logits at each timestep against the ground truth ("_clean data_") labels using cross-entropy, and that it is fine to drop the need to explicitly capture the time variable, which greatly simplifies the training objective (and becomes very similar to the standard AR-LLM training objective). Notably, the use of this cross-entropy objective is validated empirically by the strong evaluations from the LLaDA model, whose training was done with it. 

### üì∞ 4. What's come up recently in DLM research?
On another note, two interesting pieces of research have surfaced last week which I think adds to the conversation about DLMs. 

‚óºÔ∏è The first is from <a href='https://arxiv.org/abs/2507.11097' title='The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs'> (Wen et al, 2025)</a> which studies the jailbreaking vulnerability of text and multimodal MDLMs (LLaDA, Dream and MMaDA). They find that these MDLMs (see Appendix C of their paper) "_often match or surpass those of autoregressive LLMs in resisting existing jailbreak attack methods_", which is ideal. However, they also found that it is possible to use AR-LLMs (GPT4o or a 7B-parameter Qwen model) few-shot prompting to generate "mid-flight" unmasked sequences (i.e. $$\hat{x}_{t}, 0 < t < T$$) which an MDLM would go on to unmask jailbroken content (see example on right column). Notably, they tested their method on several jailbreaking benchmarks and established similar findings of such behaviour across MDLMs, including going from $$\leq$$ 1% success on JailbreakBench to $$\geq$$ 99% success. They also found that simply extending the length of the sequence made it possible to bring the MDLM from initial refusal to a jailbreak outcome (see next example on right column). These findings flag the need for further efforts to study DLM jailbreaking, to better understand and find ways to mitigate such safety weaknesses in them.

{% marginfigure "marginfigure-jailbreak" "assets/img/jailbreak_llada.png" "Source: jail breaking example -- <a href='https://arxiv.org/abs/2507.11097' title='The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs'> (Wen et al, 2025)</a>"%}

{% marginfigure "marginfigure-jailbreak-longer" "assets/img/jailbreak_longergen.png" "Source: jail breaking example -- <a href='https://arxiv.org/abs/2507.11097' title='The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs'>(Wen et al, 2025)</a>. _This finding indicates some conditional dependence for generating refusal content which is tied to max sequence length seen at training, i.e. this might be resolvable by taking steps to disconnect this dependence during training._"%}

‚óºÔ∏è The other work <a href='https://arxiv.org/abs/2507.15857v1' title='Diffusion Beats Autoregressive in Data-Constrained Settings'>(Prabhudesai et al, 2025)</a> studies the compute-data Pareto frontier of DLMs and 100 comparable AR-LLMs. Specifically, they trained 100 MDLMs and AR-LLMs (ranging in size from 7M- to 2.5B-parameters) on the English C4 corpus (at data scales of between 25 to 100M tokens) for up to 800 epochs. From their study, they found that initially, at low epoch counts, AR-LLMs outperforms DLMs; but as repeated passes over the data is carried out, DLMs overtake and perform better. Their experiments allowed them to establish a potential scaling law for for DLMs, and also conclude that under data-constrained settings (for e.g. when Internet data peters out, or in sequence modeling for specialised domains/applications where available data could be at smaller scales), a DLM architecture may be better for modeling the data distribution. The findings provide useful insights that help clarify whether (and where) moving to DLMs makes sense. That said, we are still lacking an understanding of the DLM & AR-LLM differences under real-use case evaluations{% sidenote "sidenote-eval" "e.g. with suites such as [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness); in their work they only report loss curves and perplexity (NLL)." %} as well as the impact of methods that have been recent drivers of AR-LLM model improvements (such as training on synthetic data, as well as preference tuning and reinforcement learning) on DLMs.

{% marginnote "marginnote-resources" "Some useful resources for diffusion modeling: Firstly, the \"Diffusion Models\" chapters in: 
<br>‚óºÔ∏è Chapter 20 of [Deep Learning: Foundations and Concepts](https://www.bishopbook.com/). Bishop, C.M., Bishop, H. (2024). Springer.; 
<br>‚óºÔ∏è Chapter 25 of [Probabilistic Machine Learning: Advanced Topics](https://probml.github.io/pml-book/book2.html). Murphy K. P. (2023). MIT Press.; 
<br>‚óºÔ∏è Chapter 18 of [Understanding Deep Learning](https://udlbook.github.io/udlbook/). Prince, S. J. D. (2024). MIT Press. 
<br>_Of the three textbooks, the Murphy one (to my mind, the "bible" of probabilistic generative modeling for its breadth and depth) has the most substantial coverage of discrete diffusion modeling, and the Bishop one is (in my opinion) the most accessibly written plus it also comes with helpful sections on score matching and guidance; though it helped to triangulate information between the three as much as possible._
<br>Secondly, it also helps to start with the score-matching diffusion models that were developed for image generation and go on to discrete case. To help: the diffusion and flow modules of the CS236 class taught by Stefano Ermon could be very useful for putting the parts on together.
<br>‚óºÔ∏è [Stanford CS236: Deep Generative Models 2023 playlist](https://www.youtube.com/playlist?list=PLoROMvodv4rPOWA-omMM6STXaWW4FvJT8)
Finally, this survey paper also goes deep into the various aspects of DLMs:
<br>‚óºÔ∏è [Discrete Diffusion in Large Language and Multimodal Models: A Survey](https://arxiv.org/abs/2506.13759?)"%}

{% marginnote "marginnote-notes"
"<ins>__Some notes:__</ins> It seems reasonable to consider combining UDLM and MDLM, after all the latter is just adding an additional state ```[MASK]``` and enforcing fixedness once this state is reached/exited. I am wondering if it might make sense to add the ```[MASK]``` token as well as permit transitions to and from it across the timesteps (i.e. UDLM+```[MASK]```), but with some constraints that the overall ratio of ```[MASK]``` tokens must monotonically increase over time in the forward process, which could address the \"self-correction\" limitation of MDLM (see [above](#-2-apple-to-apple-whats-the-benefit-of-one-over-another)). <a href='https://arxiv.org/abs/2107.03006' title='Structured Denoising Diffusion Models in Discrete State-Spaces'>(Austin et al, 2021)</a> (see Appendix A.2.6 and B.2.1 as well as Figure 4 (upper) there) stated that they carried out some ablations on the text8 dataset that touched on this -- for e.g. by applying $$e_m$$ a separate one-hot vector with 1 on ```[MASK]``` and 0 elsewhere -- but do not seem to have included the results to show how UDLM+```[MASK]``` performs over MDLM. _Although this change might impact the simplification of the loss objective to the use of cross-entropy against ground truth tokens as established by MD4, M-DLM and RADD. (see for e.g. ¬ß3.1 of the RADD paper)_" %}

### üëâ 4. What‚Äôs next?
In this post, I have covered the three broad classes of DLMs, discussed what their differences mean, then briefly described the training procedure of MDLMs, before ending on some recent DLM research and their broader implications. In the next post, I will walk through the reverse process used for generation in DLMs, situate generation with DLMs against existing efficient serving methods for AR-LLMs, and then look at the a few recent advanced sampling techniques proposed (such as block-wise/semi-autoregessivity and caching). In the post after that, I will cover preference tuning and reinforcement learning of these DLMs.

